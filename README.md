Persistent Memory Chatbot ğŸ¤–

A production-ready,LLM-powered chatbot that remembers long-term conversations using RAG (Retrieval-Augmented Generation) and integrates stylish UI,monitoring and scalable memory storage.
---

ğŸš€ Features

âœ… LLaMA / OpenAI GPT API backend

âœ… Pinecone vector database for conversation memory

âœ… Retrieval-Augmented Generation (RAG) pipeline

âœ… Streamlit frontend with modern animated design

âœ… OpenTelemetry tracing & monitoring

âœ… Modular, scalable Python codebase

âœ… Optional summarization to compress memory

âœ… NSFW-ready architecture for safety layers

---

ğŸ› ï¸ Tech Stack

Backend: FastAPI, OpenAI API, SentenceTransformers, Pinecone, LangChain (optional)

Frontend: Streamlit, Custom CSS

Memory: Pinecone Vector Database

Monitoring: OpenTelemetry

LLMs: OpenAI GPT / LLaMA / Mistral

Optional: LangFuse, LangGraph



---

ğŸ“¦ File Structure

persistent_memory_chatbot/
â”œâ”€â”€ app/                    # Backend API code
â”œâ”€â”€ models/                 # LLM & summarizer modules
â”œâ”€â”€ db/                     # Vector DB interfaces
â”œâ”€â”€ frontend/               # Streamlit UI + CSS
â”œâ”€â”€ monitoring/             # Tracing via OpenTelemetry
â”œâ”€â”€ tests/                  # Unit tests (to be created)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile (optional)
â”œâ”€â”€ README.md


---

âš™ï¸ Setup Instructions

1. Clone Repo:
git clone https://github.com/your-username/persistent-memory-chatbot.git


2. Install Dependencies:
pip install -r requirements.txt


3. Configure API Keys:
Create a .env file in project root:

OPENAI_API_KEY=your-openai-api-key
VECTOR_DB_TYPE=pinecone
VECTOR_DB_INDEX=chatbot_memory


4. Run Backend API:
uvicorn app.main:app --reload


5. Run Frontend:
In a separate terminal:
streamlit run frontend/app.py

---

ğŸ“Š Monitoring

Traces are logged via OpenTelemetry Console Exporter.

Extend to support Jaeger/Prometheus via monitoring/tracing.py.


---

ğŸ† Project Highlights

Persistent, evolving chatbot memory.

Elegant, modern UI for conversations.

Modular and production-scalable design.

Extendable with summarization, safety layers, or multi-agent architectures.



---

ğŸ¤ Contributing

1. Fork the repo


2. Create your feature branch (git checkout -b feature/new-feature)


3. Commit changes (git commit -m 'Add new feature')


4. Push to branch (git push origin feature/new-feature)


5. Create a Pull Request




---

ğŸ“„ License

MIT License Â© 2025 Robert Chonge
